{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ddk0O-ffv9I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.display.max_rows = 20\n",
        "pd.options.display.max_colwidth = 80\n",
        "pd.options.display.max_columns = 20\n",
        "np.random.seed(12345)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc(\"figure\", figsize=(10, 6))\n",
        "np.set_printoptions(precision=4, suppress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Wrangling: Join, Combine, and Reshape"
      ],
      "metadata": {
        "id": "RI2h5wVmf3pT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Hierarchical Indexing\n",
        " Hierarchical indexing is an important feature of pandas that enables you to have\n",
        " multiple (two or more) index levels on an axis. Another way of thinking about it\n",
        " is that it provides a way for you to work with higher dimensional data in a lower\n",
        " dimensional form. Let’s start with a simple example: create a Series with a list of lists\n",
        " (or arrays) as the index:"
      ],
      "metadata": {
        "id": "uN5pUB0Cf-wb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttbsdUwlfv9J"
      },
      "outputs": [],
      "source": [
        "data = pd.Series(np.random.uniform(size=9),\n",
        "                 index=[[\"a\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\", \"d\", \"d\"],\n",
        "                        [1, 2, 3, 1, 3, 1, 2, 2, 3]])\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " What you’re seeing is a prettified view of a Series with a MultiIndex as its index. The\n",
        " “gaps” in the index display mean “use the label directly above”:"
      ],
      "metadata": {
        "id": "l5HoIax4gGTe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJcAKBQpfv9J"
      },
      "outputs": [],
      "source": [
        "data.index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a hierarchically indexed object, so-called partial indexing is possible, enabling\n",
        " you to concisely select subsets of the data:"
      ],
      "metadata": {
        "id": "cZhQZNkYgJK8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThfyrczWfv9J"
      },
      "outputs": [],
      "source": [
        "data[\"b\"]\n",
        "data[\"b\":\"c\"]\n",
        "data.loc[[\"b\", \"d\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Selection is even possible from an “inner” level. Here I select all of the values having\n",
        " the value 2 from the second index level:"
      ],
      "metadata": {
        "id": "oFYe6bgEgM3w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wNUi77Afv9J"
      },
      "outputs": [],
      "source": [
        "data.loc[:, 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Hierarchical indexing plays an important role in reshaping data and in group-based\n",
        " operations like forming a pivot table. For example, you can rearrange this data into a\n",
        " DataFrame using its unstack method:"
      ],
      "metadata": {
        "id": "NYh7QVjVgO3U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TztD5V6zfv9K"
      },
      "outputs": [],
      "source": [
        "data.unstack()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The inverse operation of unstack is stack:"
      ],
      "metadata": {
        "id": "ThZ44Sw6gQ6P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIMhcKZVfv9K"
      },
      "outputs": [],
      "source": [
        "data.unstack().stack()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a DataFrame, either axis can have a hierarchical index:"
      ],
      "metadata": {
        "id": "03glIxivgUqC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbuJiCF3fv9K"
      },
      "outputs": [],
      "source": [
        "frame = pd.DataFrame(np.arange(12).reshape((4, 3)),\n",
        "                     index=[[\"a\", \"a\", \"b\", \"b\"], [1, 2, 1, 2]],\n",
        "                     columns=[[\"Ohio\", \"Ohio\", \"Colorado\"],\n",
        "                              [\"Green\", \"Red\", \"Green\"]])\n",
        "frame"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The hierarchical levels can have names (as strings or any Python objects). If so, these\n",
        " will show up in the console output"
      ],
      "metadata": {
        "id": "Q8WifVVagWlG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1ynnOscfv9K"
      },
      "outputs": [],
      "source": [
        "frame.index.names = [\"key1\", \"key2\"]\n",
        "frame.columns.names = [\"state\", \"color\"]\n",
        "frame"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " You can see how many levels an index has by accessing its nlevels attribute"
      ],
      "metadata": {
        "id": "ILOCUhVVgaU8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mbwslobbfv9K"
      },
      "outputs": [],
      "source": [
        "frame.index.nlevels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " With partial column indexing you can similarly select groups of columns"
      ],
      "metadata": {
        "id": "P7NivmDrgcEP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCyCZSrCfv9K"
      },
      "outputs": [],
      "source": [
        "frame[\"Ohio\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reordering and Sorting Levels\n",
        "At times you may need to rearrange the order of the levels on an axis or sort the data\n",
        " by the values in one specific level. The swaplevel method takes two level numbers\n",
        " or names and returns a new object with the levels interchanged (but the data is\n",
        " otherwise unaltered):"
      ],
      "metadata": {
        "id": "d2BTQNoxglvG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCupX2tgfv9K"
      },
      "outputs": [],
      "source": [
        "frame.swaplevel(\"key1\", \"key2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " sort_index by default sorts the data lexicographically using all the index levels, but\n",
        " you can choose to use only a single level or a subset of levels to sort by passing the\n",
        " level argument. For example:"
      ],
      "metadata": {
        "id": "lQ8lCzZagsiE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tkeTBvDfv9L"
      },
      "outputs": [],
      "source": [
        "frame.sort_index(level=1)\n",
        "frame.swaplevel(0, 1).sort_index(level=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Summary Statistics by Level\n",
        "\n",
        " Many descriptive and summary statistics on DataFrame and Series have a level\n",
        " option in which you can specify the level you want to aggregate by on a particular\n",
        " axis. Consider the above DataFrame; we can aggregate by level on either the rows or\n",
        " columns, like so:\n",
        "\n"
      ],
      "metadata": {
        "id": "28LB9t6bgvWO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrzDLOAgfv9L"
      },
      "outputs": [],
      "source": [
        "frame.groupby(level=\"key2\").sum()\n",
        "frame.groupby(level=\"color\", axis=\"columns\").sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Indexing with a DataFrame’s columns\n",
        "\n",
        "  It’s not unusual to want to use one or more columns from a DataFrame as the\n",
        " row index; alternatively, you may wish to move the row index into the DataFrame’s\n",
        " columns. Here’s an example DataFrame:"
      ],
      "metadata": {
        "id": "Sx3ISEDFg4Wq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9Whd3i_fv9L"
      },
      "outputs": [],
      "source": [
        "frame = pd.DataFrame({\"a\": range(7), \"b\": range(7, 0, -1),\n",
        "                      \"c\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
        "                            \"two\", \"two\"],\n",
        "                      \"d\": [0, 1, 2, 0, 1, 2, 3]})\n",
        "frame"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " DataFrame’s set_index function will create a new DataFrame using one or more of\n",
        " its columns as the index:"
      ],
      "metadata": {
        "id": "ioVExolMg-lQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjXfzGb1fv9L"
      },
      "outputs": [],
      "source": [
        "frame2 = frame.set_index([\"c\", \"d\"])\n",
        "frame2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the columns are removed from the DataFrame, though you can leave\n",
        " them in by passing drop=False to set_index:"
      ],
      "metadata": {
        "id": "O9B-SVoahA5t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2Mnvxicfv9L"
      },
      "outputs": [],
      "source": [
        "frame.set_index([\"c\", \"d\"], drop=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " reset_index, on the other hand, does the opposite of set_index; the hierarchical\n",
        " index levels are moved into the columns:"
      ],
      "metadata": {
        "id": "pBhsDtDkhDMy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_Lee-cCfv9L"
      },
      "outputs": [],
      "source": [
        "frame2.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining and Merging Datasets\n",
        " Data contained in pandas objects can be combined in a number of ways:\n",
        " # pandas.merge\n",
        " Connect rows in DataFrames based on one or more keys. This will be familiar\n",
        " to users of SQL or other relational databases, as it implements database join\n",
        " operations.\n",
        " # pandas.concat\n",
        " Concatenate or “stack” objects together along an axis.\n",
        " # combine_first\n",
        " Splice together overlapping data to fill in missing values in one object with values\n",
        " from another.\n",
        " I will address each of these and give a number of examples. They’ll be utilized in\n",
        " examples throughout the rest of the book."
      ],
      "metadata": {
        "id": "_FtyP4mJhL0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Database-Style DataFrame Joins\n",
        " Merge or join operations combine datasets by linking rows using one or more keys.\n",
        " These operations are particularly important in relational databases (e.g., SQL-based).\n",
        " The pandas.merge function in pandas is the main entry point for using these algo\n",
        "rithms on your data.\n",
        " Let’s start with a simple example:"
      ],
      "metadata": {
        "id": "B7uVV5oFhXCg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hlY5iebfv9L"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"a\", \"b\"],\n",
        "                    \"data1\": pd.Series(range(7), dtype=\"Int64\")})\n",
        "df2 = pd.DataFrame({\"key\": [\"a\", \"b\", \"d\"],\n",
        "                    \"data2\": pd.Series(range(3), dtype=\"Int64\")})\n",
        "df1\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " This is an example of a many-to-one join; the data in df1 has multiple rows labeled\n",
        " a and b, whereas df2 has only one row for each value in the key column. Calling\n",
        " pandas.merge with these objects, we obtain:"
      ],
      "metadata": {
        "id": "4Q_SRHkDhbC8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omL77Lwhfv9L"
      },
      "outputs": [],
      "source": [
        "pd.merge(df1, df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that I didn’t specify which column to join on. If that information is not\n",
        " specified, pandas.merge uses the overlapping column names as the keys. It’s a good\n",
        " practice to specify explicitly, though:"
      ],
      "metadata": {
        "id": "R23ZImAaheQM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzqX2n9Afv9L"
      },
      "outputs": [],
      "source": [
        "pd.merge(df1, df2, on=\"key\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " In general, the order of column output in pandas.merge operations is unspecified.\n",
        " If the column names are different in each object, you can specify them separately:"
      ],
      "metadata": {
        "id": "z996FtvVhg28"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-4lM3x8fv9L"
      },
      "outputs": [],
      "source": [
        "df3 = pd.DataFrame({\"lkey\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"a\", \"b\"],\n",
        "                    \"data1\": pd.Series(range(7), dtype=\"Int64\")})\n",
        "df4 = pd.DataFrame({\"rkey\": [\"a\", \"b\", \"d\"],\n",
        "                    \"data2\": pd.Series(range(3), dtype=\"Int64\")})\n",
        "pd.merge(df3, df4, left_on=\"lkey\", right_on=\"rkey\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " You may notice that the \"c\" and \"d\" values and associated data are missing from\n",
        " the result. By default, pandas.merge does an \"inner\" join; the keys in the result are\n",
        " the intersection, or the common set found in both tables. Other possible options are\n",
        " \"left\", \"right\", and \"outer\". The outer join takes the union of the keys, combining\n",
        " the effect of applying both left and right joins"
      ],
      "metadata": {
        "id": "y99zhcG3hjI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16N2KlI6fv9L"
      },
      "outputs": [],
      "source": [
        "pd.merge(df1, df2, how=\"outer\")\n",
        "pd.merge(df3, df4, left_on=\"lkey\", right_on=\"rkey\", how=\"outer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " how=\"inner\" Use only the key combinations observed in both tables\n",
        "\n",
        " how=\"left\" Use all key combinations found in the left table\n",
        "\n",
        " how=\"right\" Use all key combinations found in the right table\n",
        "\n",
        " how=\"outer\" Use all key combinations observed in both tables together\n"
      ],
      "metadata": {
        "id": "N8z7kSYqhrEu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yatTuWaAfv9L"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"b\"],\n",
        "                    \"data1\": pd.Series(range(6), dtype=\"Int64\")})\n",
        "df2 = pd.DataFrame({\"key\": [\"a\", \"b\", \"a\", \"b\", \"d\"],\n",
        "                    \"data2\": pd.Series(range(5), dtype=\"Int64\")})\n",
        "df1\n",
        "df2\n",
        "pd.merge(df1, df2, on=\"key\", how=\"left\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Since there were three \"b\" rows in the left DataFrame and two in the right one, there\n",
        " are six \"b\" rows in the result. The join method passed to the how keyword argument\n",
        " affects only the distinct key values appearing in the result:"
      ],
      "metadata": {
        "id": "tNNwySljhwLm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKtOtfS1fv9M"
      },
      "outputs": [],
      "source": [
        "pd.merge(df1, df2, how=\"inner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " To merge with multiple keys, pass a list of column names:"
      ],
      "metadata": {
        "id": "Xd6XVGj7hyOw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou06NgmMfv9M"
      },
      "outputs": [],
      "source": [
        "left = pd.DataFrame({\"key1\": [\"foo\", \"foo\", \"bar\"],\n",
        "                     \"key2\": [\"one\", \"two\", \"one\"],\n",
        "                     \"lval\": pd.Series([1, 2, 3], dtype='Int64')})\n",
        "right = pd.DataFrame({\"key1\": [\"foo\", \"foo\", \"bar\", \"bar\"],\n",
        "                      \"key2\": [\"one\", \"one\", \"one\", \"two\"],\n",
        "                      \"rval\": pd.Series([4, 5, 6, 7], dtype='Int64')})\n",
        "pd.merge(left, right, on=[\"key1\", \"key2\"], how=\"outer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A last issue to consider in merge operations is the treatment of overlapping column\n",
        " names. For example:"
      ],
      "metadata": {
        "id": "rBXI3PJLh17s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRPhyUNLfv9M"
      },
      "outputs": [],
      "source": [
        "pd.merge(left, right, on=\"key1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " While you can address the overlap manually (see the section “Renaming Axis\n",
        " Indexes” on page 214 for renaming axis labels), pandas.merge has a suffixes option\n",
        " for specifying strings to append to overlapping names in the left and right DataFrame\n",
        " objects:"
      ],
      "metadata": {
        "id": "Y-tbdti6h4jw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oJDv0Zffv9M"
      },
      "outputs": [],
      "source": [
        "pd.merge(left, right, on=\"key1\", suffixes=(\"_left\", \"_right\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Merging on Index\n",
        " In some cases, the merge key(s) in a DataFrame will be found in its index (row\n",
        " labels). In this case, you can pass left_index=True or right_index=True (or both) to\n",
        " indicate that the index should be used as the merge key:"
      ],
      "metadata": {
        "id": "4a-8q6iLh-IW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81ZwyQVRfv9M"
      },
      "outputs": [],
      "source": [
        "left1 = pd.DataFrame({\"key\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"c\"],\n",
        "                      \"value\": pd.Series(range(6), dtype=\"Int64\")})\n",
        "right1 = pd.DataFrame({\"group_val\": [3.5, 7]}, index=[\"a\", \"b\"])\n",
        "left1\n",
        "right1\n",
        "pd.merge(left1, right1, left_on=\"key\", right_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Since the default merge method is to intersect the join keys, you can instead form the\n",
        " union of them with an outer join:"
      ],
      "metadata": {
        "id": "f3x5FiIRiNQm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2R1-owifv9M"
      },
      "outputs": [],
      "source": [
        "pd.merge(left1, right1, left_on=\"key\", right_index=True, how=\"outer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " With hierarchically indexed data, things are more complicated, as joining on index is\n",
        " equivalent to a multiple-key merge:"
      ],
      "metadata": {
        "id": "HO_CBUV8iO8K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub_7aTc6fv9M"
      },
      "outputs": [],
      "source": [
        "lefth = pd.DataFrame({\"key1\": [\"Ohio\", \"Ohio\", \"Ohio\",\n",
        "                               \"Nevada\", \"Nevada\"],\n",
        "                      \"key2\": [2000, 2001, 2002, 2001, 2002],\n",
        "                      \"data\": pd.Series(range(5), dtype=\"Int64\")})\n",
        "righth_index = pd.MultiIndex.from_arrays(\n",
        "    [\n",
        "        [\"Nevada\", \"Nevada\", \"Ohio\", \"Ohio\", \"Ohio\", \"Ohio\"],\n",
        "        [2001, 2000, 2000, 2000, 2001, 2002]\n",
        "    ]\n",
        ")\n",
        "righth = pd.DataFrame({\"event1\": pd.Series([0, 2, 4, 6, 8, 10], dtype=\"Int64\",\n",
        "                                           index=righth_index),\n",
        "                       \"event2\": pd.Series([1, 3, 5, 7, 9, 11], dtype=\"Int64\",\n",
        "                                           index=righth_index)})\n",
        "lefth\n",
        "righth"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " In this case, you have to indicate multiple columns to merge on as a list (note the\n",
        " handling of duplicate index values with how=\"outer\"):"
      ],
      "metadata": {
        "id": "WnOKQry0iR7I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbURYYkmfv9M"
      },
      "outputs": [],
      "source": [
        "pd.merge(lefth, righth, left_on=[\"key1\", \"key2\"], right_index=True)\n",
        "pd.merge(lefth, righth, left_on=[\"key1\", \"key2\"],\n",
        "         right_index=True, how=\"outer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Using the indexes of both sides of the merge is also possible:"
      ],
      "metadata": {
        "id": "GtBoU3_wiT_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXfiFa-dfv9M"
      },
      "outputs": [],
      "source": [
        "left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]],\n",
        "                     index=[\"a\", \"c\", \"e\"],\n",
        "                     columns=[\"Ohio\", \"Nevada\"]).astype(\"Int64\")\n",
        "right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],\n",
        "                      index=[\"b\", \"c\", \"d\", \"e\"],\n",
        "                      columns=[\"Missouri\", \"Alabama\"]).astype(\"Int64\")\n",
        "left2\n",
        "right2\n",
        "pd.merge(left2, right2, how=\"outer\", left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " DataFrame has a join instance method to simplify merging by index. It can also be\n",
        " used to combine many DataFrame objects having the same or similar indexes but\n",
        " nonoverlapping columns. In the prior example, we could have written:"
      ],
      "metadata": {
        "id": "XIikWasfiXiU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpPE8S81fv9M"
      },
      "outputs": [],
      "source": [
        "left2.join(right2, how=\"outer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compared with pandas.merge, DataFrame’s join method performs a left join on the\n",
        " join keys by default. It also supports joining the index of the passed DataFrame on\n",
        " one of the columns of the calling DataFrame:"
      ],
      "metadata": {
        "id": "9CPjv0oNiZYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU5XCdmQfv9N"
      },
      "outputs": [],
      "source": [
        "left1.join(right1, on=\"key\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " You can think of this method as joining data “into” the object whose join method\n",
        " was called.\n",
        " Lastly, for simple index-on-index merges, you can pass a list of DataFrames to join\n",
        " as an alternative to using the more general pandas.concat function described in the\n",
        " next section:"
      ],
      "metadata": {
        "id": "Bg7PRoIGibnS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsYzmDc9fv9N"
      },
      "outputs": [],
      "source": [
        "another = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [16., 17.]],\n",
        "                       index=[\"a\", \"c\", \"e\", \"f\"],\n",
        "                       columns=[\"New York\", \"Oregon\"])\n",
        "another\n",
        "left2.join([right2, another])\n",
        "left2.join([right2, another], how=\"outer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Concatenating Along an Axis\n",
        "\n",
        " Another kind of data combination operation is referred to interchangeably as concat\n",
        "enation or stacking. NumPy’s concatenate function can do this with NumPy arrays:"
      ],
      "metadata": {
        "id": "UJC9uuaDig6E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "odAzogg1inW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8Qne3DKfv9N"
      },
      "outputs": [],
      "source": [
        "arr = np.arange(12).reshape((3, 4))\n",
        "arr\n",
        "np.concatenate([arr, arr], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of pandas objects such as Series and DataFrame, having labeled axes\n",
        " enable you to further generalize array concatenation. In particular, you have a num\n",
        "ber of additional concerns:\n",
        "\n",
        "\n",
        " • If the objects are indexed differently on the other axes, should we combine the\n",
        " distinct elements in these axes or use only the values in common?\n",
        "\n",
        "\n",
        " • Do the concatenated chunks of data need to be identifiable as such in the result\n",
        "ing object?\n",
        "\n",
        "\n",
        " • Does the “concatenation axis” contain data that needs to be preserved? In\n",
        " many cases, the default integer labels in a DataFrame are best discarded during\n",
        " concatenation.\n",
        "\n",
        " The concat function in pandas provides a consistent way to address each of these\n",
        " questions. I’ll give a number of examples to illustrate how it works. Suppose we have\n",
        " three Series with no index overlap:"
      ],
      "metadata": {
        "id": "oftNi8KAim5T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCotArdvfv9N"
      },
      "outputs": [],
      "source": [
        "s1 = pd.Series([0, 1], index=[\"a\", \"b\"], dtype=\"Int64\")\n",
        "s2 = pd.Series([2, 3, 4], index=[\"c\", \"d\", \"e\"], dtype=\"Int64\")\n",
        "s3 = pd.Series([5, 6], index=[\"f\", \"g\"], dtype=\"Int64\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Calling pandas.concat with these objects in a list glues together the values and\n",
        " indexes:"
      ],
      "metadata": {
        "id": "dTC4uzOSiy2M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWGDQQ0Mfv9N"
      },
      "outputs": [],
      "source": [
        "s1\n",
        "s2\n",
        "s3\n",
        "pd.concat([s1, s2, s3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " By default, pandas.concat works along axis=\"index\", producing another Series. If\n",
        " you pass axis=\"columns\", the result will instead be a DataFrame:"
      ],
      "metadata": {
        "id": "XMxqdQZ8i1Iw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyi67eptfv9Q"
      },
      "outputs": [],
      "source": [
        "pd.concat([s1, s2, s3], axis=\"columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " In this case there is no overlap on the other axis, which as you can see is the\n",
        " union (the \"outer\" join) of the indexes. You can instead intersect them by passing\n",
        " join=\"inner\":"
      ],
      "metadata": {
        "id": "IBeK__vWi3V4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONB5nFSBfv9Q"
      },
      "outputs": [],
      "source": [
        "s4 = pd.concat([s1, s3])\n",
        "s4\n",
        "pd.concat([s1, s4], axis=\"columns\")\n",
        "pd.concat([s1, s4], axis=\"columns\", join=\"inner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " In this last example, the \"f\" and \"g\" labels disappeared because of the join=\"inner\"\n",
        " option."
      ],
      "metadata": {
        "id": "9n5cpCwwi7MY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A potential issue is that the concatenated pieces are not identifiable in the result.\n",
        " Suppose instead you wanted to create a hierarchical index on the concatenation axis.\n",
        " To do this, use the keys argument:"
      ],
      "metadata": {
        "id": "-cmkjAETi9-k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUiV30kRfv9Q"
      },
      "outputs": [],
      "source": [
        "result = pd.concat([s1, s1, s3], keys=[\"one\", \"two\", \"three\"])\n",
        "result\n",
        "result.unstack()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " In the case of combining Series along axis=\"columns\", the keys become the Data\n",
        "Frame column headers:"
      ],
      "metadata": {
        "id": "5wb1x6ZTjBVQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGYvmzMZfv9Q"
      },
      "outputs": [],
      "source": [
        "pd.concat([s1, s2, s3], axis=\"columns\", keys=[\"one\", \"two\", \"three\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The same logic extends to DataFrame objects:"
      ],
      "metadata": {
        "id": "R5RTyqVQjDGA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyR8H2wWfv9R"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame(np.arange(6).reshape(3, 2), index=[\"a\", \"b\", \"c\"],\n",
        "                   columns=[\"one\", \"two\"])\n",
        "df2 = pd.DataFrame(5 + np.arange(4).reshape(2, 2), index=[\"a\", \"c\"],\n",
        "                   columns=[\"three\", \"four\"])\n",
        "df1\n",
        "df2\n",
        "pd.concat([df1, df2], axis=\"columns\", keys=[\"level1\", \"level2\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Here the keys argument is used to create a hierarchical index where the first level can\n",
        " be used to identify each of the concatenated DataFrame objects.\n",
        " If you pass a dictionary of objects instead of a list, the dictionary’s keys will be used\n",
        " for the keys option:"
      ],
      "metadata": {
        "id": "7aKFgrN0jITe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmC3ft7Kfv9R"
      },
      "outputs": [],
      "source": [
        "pd.concat({\"level1\": df1, \"level2\": df2}, axis=\"columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " There are additional arguments governing how the hierarchical index is created\n",
        " (see Table 8-3). For example, we can name the created axis levels with the names\n",
        " argument:"
      ],
      "metadata": {
        "id": "yLOI3k-9jKsY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEftkLo4fv9R"
      },
      "outputs": [],
      "source": [
        "pd.concat([df1, df2], axis=\"columns\", keys=[\"level1\", \"level2\"],\n",
        "          names=[\"upper\", \"lower\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " A last consideration concerns DataFrames in which the row index does not contain\n",
        " any relevant data:"
      ],
      "metadata": {
        "id": "eLJLL8f5jNFa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-w2ipFHfv9R"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame(np.random.standard_normal((3, 4)),\n",
        "                   columns=[\"a\", \"b\", \"c\", \"d\"])\n",
        "df2 = pd.DataFrame(np.random.standard_normal((2, 3)),\n",
        "                   columns=[\"b\", \"d\", \"a\"])\n",
        "df1\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " In this case, you can pass ignore_index=True, which discards the indexes from each\n",
        " DataFrame and concatenates the data in the columns only, assigning a new default\n",
        " index:"
      ],
      "metadata": {
        "id": "dsR5m0EIjQI-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ewb5YNPfv9R"
      },
      "outputs": [],
      "source": [
        "pd.concat([df1, df2], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Combining Data with Overlap\n",
        " There is another data combination situation that can’t be expressed as either a merge\n",
        " or concatenation operation. You may have two datasets with indexes that overlap in\n",
        " full or in part. As a motivating example, consider NumPy’s where function, which\n",
        " performs the array-oriented equivalent of an if-else expression:"
      ],
      "metadata": {
        "id": "yieoRTmOjT9V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wopeGRYSfv9R"
      },
      "outputs": [],
      "source": [
        "a = pd.Series([np.nan, 2.5, 0.0, 3.5, 4.5, np.nan],\n",
        "              index=[\"f\", \"e\", \"d\", \"c\", \"b\", \"a\"])\n",
        "b = pd.Series([0., np.nan, 2., np.nan, np.nan, 5.],\n",
        "              index=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n",
        "a\n",
        "b\n",
        "np.where(pd.isna(a), b, a)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Here, whenever values in a are null, values from b are selected, otherwise the non\n",
        "null values from a are selected. Using numpy.where does not check whether the index\n",
        " labels are aligned or not (and does not even require the objects to be the same\n",
        " length), so if you want to line up values by index, use the Series combine_first\n",
        " method:"
      ],
      "metadata": {
        "id": "hWxpE3n0jXCz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFFOXBctfv9R"
      },
      "outputs": [],
      "source": [
        "a.combine_first(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Reshaping and Pivoting\n",
        " There are a number of basic operations for rearranging tabular data. These are\n",
        " referred to as reshape or pivot operations.\n",
        "\n",
        " # Reshaping with Hierarchical Indexing\n",
        " Hierarchical indexing provides a consistent way to rearrange data in a DataFrame.\n",
        " There are two primary actions:\n",
        " # stack\n",
        " This “rotates” or pivots from the columns in the data to the rows.\n",
        " # unstack\n",
        " This pivots from the rows into the columns.\n",
        " With DataFrames, combine_first does the same thing column by column, so you\n",
        " can think of it as “patching” missing data in the calling object with data from the\n",
        " object you pass:"
      ],
      "metadata": {
        "id": "ifX-luxdjYpd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fje49tyfv9R"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame({\"a\": [1., np.nan, 5., np.nan],\n",
        "                    \"b\": [np.nan, 2., np.nan, 6.],\n",
        "                    \"c\": range(2, 18, 4)})\n",
        "df2 = pd.DataFrame({\"a\": [5., 4., np.nan, 3., 7.],\n",
        "                    \"b\": [np.nan, 3., 4., 6., 8.]})\n",
        "df1\n",
        "df2\n",
        "df1.combine_first(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I’ll illustrate these operations through a series of examples. Consider a small Data\n",
        "Frame with string arrays as row and column indexes:"
      ],
      "metadata": {
        "id": "E_V_qB3Fjgld"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5agT-pNwfv9R"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame(np.arange(6).reshape((2, 3)),\n",
        "                    index=pd.Index([\"Ohio\", \"Colorado\"], name=\"state\"),\n",
        "                    columns=pd.Index([\"one\", \"two\", \"three\"],\n",
        "                    name=\"number\"))\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Using the stack method on this data pivots the columns into the rows, producing a\n",
        " Series:"
      ],
      "metadata": {
        "id": "q1kZvbuYjrba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdNiA8Kdfv9R"
      },
      "outputs": [],
      "source": [
        "result = data.stack()\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " From a hierarchically indexed Series, you can rearrange the data back into a Data\n",
        "Frame with unstack:"
      ],
      "metadata": {
        "id": "uxqOqedQjts2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idLVnk33fv9S"
      },
      "outputs": [],
      "source": [
        "result.unstack()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " By default, the innermost level is unstacked (same with stack). You can unstack a\n",
        " different level by passing a level number or name:"
      ],
      "metadata": {
        "id": "H82Q6KVwjwFD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpuQaz4ifv9S"
      },
      "outputs": [],
      "source": [
        "result.unstack(level=0)\n",
        "result.unstack(level=\"state\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Unstacking might introduce missing data if all of the values in the level aren’t found\n",
        " in each subgroup:"
      ],
      "metadata": {
        "id": "kVNdCpQJjyBr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V61Y3SMsfv9S"
      },
      "outputs": [],
      "source": [
        "s1 = pd.Series([0, 1, 2, 3], index=[\"a\", \"b\", \"c\", \"d\"], dtype=\"Int64\")\n",
        "s2 = pd.Series([4, 5, 6], index=[\"c\", \"d\", \"e\"], dtype=\"Int64\")\n",
        "data2 = pd.concat([s1, s2], keys=[\"one\", \"two\"])\n",
        "data2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Stacking filters out missing data by default, so the operation is more easily invertible:"
      ],
      "metadata": {
        "id": "JroJbV_ojz9a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSJgZXCqfv9S"
      },
      "outputs": [],
      "source": [
        "data2.unstack()\n",
        "data2.unstack().stack()\n",
        "data2.unstack().stack(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " When you unstack in a DataFrame, the level unstacked becomes the lowest level in\n",
        " the result"
      ],
      "metadata": {
        "id": "PADGpNR5j2BT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLvRKDvrfv9S"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"left\": result, \"right\": result + 5},\n",
        "                  columns=pd.Index([\"left\", \"right\"], name=\"side\"))\n",
        "df\n",
        "df.unstack(level=\"state\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " As with unstack, when calling stack we can indicate the name of the axis to stack:"
      ],
      "metadata": {
        "id": "WXRr7eBEj4E7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LBooYnFfv9S"
      },
      "outputs": [],
      "source": [
        "df.unstack(level=\"state\").stack(level=\"side\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pivoting “Long” to “Wide” Format\n",
        " A common way to store multiple time series in databases and CSV files is what\n",
        " is sometimes called long or stacked format. In this format, individual values are\n",
        " represented by a single row in a table rather than multiple values per row.\n",
        "\n",
        "Let’s load some example data and do a small amount of time series wrangling and\n",
        " other data cleaning:"
      ],
      "metadata": {
        "id": "xbsIEji5j67Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXSzNiEofv9S"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"examples/macrodata.csv\")\n",
        "data = data.loc[:, [\"year\", \"quarter\", \"realgdp\", \"infl\", \"unemp\"]]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " First, I use pandas.PeriodIndex (which represents time intervals rather than points\n",
        " in time), discussed in more detail in Chapter 11, to combine the year and quarter\n",
        " columns to set the index to consist of datetime values at the end of each quarter:"
      ],
      "metadata": {
        "id": "Lme3BT4FkBjJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY-gQQFbfv9S"
      },
      "outputs": [],
      "source": [
        "periods = pd.PeriodIndex(year=data.pop(\"year\"),\n",
        "                         quarter=data.pop(\"quarter\"),\n",
        "                         name=\"date\")\n",
        "periods\n",
        "data.index = periods.to_timestamp(\"D\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Here I used the pop method on the DataFrame, which returns a column while\n",
        " deleting it from the DataFrame at the same time.\n",
        " Then, I select a subset of columns and give the columns index the name \"item\":"
      ],
      "metadata": {
        "id": "9h6mBR4DkozG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHilMH-Rfv9S"
      },
      "outputs": [],
      "source": [
        "data = data.reindex(columns=[\"realgdp\", \"infl\", \"unemp\"])\n",
        "data.columns.name = \"item\"\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Lastly, I reshape with stack, turn the new index levels into columns with\n",
        " reset_index, and finally give the column containing the data values the name\n",
        " \"value\":"
      ],
      "metadata": {
        "id": "YpHy91jqksaD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obd1ns3Pfv9S"
      },
      "outputs": [],
      "source": [
        "long_data = (data.stack()\n",
        "             .reset_index()\n",
        "             .rename(columns={0: \"value\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Now, ldata looks like:"
      ],
      "metadata": {
        "id": "GZXznjuFkuKJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-_Uv9vrfv9S"
      },
      "outputs": [],
      "source": [
        "long_data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " In this so-called long format for multiple time series, each row in the table represents\n",
        " a single observation.\n",
        "\n",
        " Data is frequently stored this way in relational SQL databases, as a fixed schema (col\n",
        "umn names and data types) allows the number of distinct values in the item column\n",
        " to change as data is added to the table. In the previous example, date and item would\n",
        " usually be the primary keys (in relational database parlance), offering both relational\n",
        " integrity and easier joins. In some cases, the data may be more difficult to work with\n",
        " in this format; you might prefer to have a DataFrame containing one column per\n",
        " distinct item value indexed by timestamps in the date column. DataFrame’s pivot\n",
        " method performs exactly this transformation:"
      ],
      "metadata": {
        "id": "DkfTzw-zkzVS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqflV06Rfv9T"
      },
      "outputs": [],
      "source": [
        "pivoted = long_data.pivot(index=\"date\", columns=\"item\",\n",
        "                          values=\"value\")\n",
        "pivoted.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V-tSbd5fv9T"
      },
      "outputs": [],
      "source": [
        "long_data.index.name = None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The first two values passed are the columns to be used, respectively, as the row and\n",
        " column index, then finally an optional value column to fill the DataFrame. Suppose\n",
        " you had two value columns that you wanted to reshape simultaneously:"
      ],
      "metadata": {
        "id": "GXkAOmBfk32L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgIWzECkfv9T"
      },
      "outputs": [],
      "source": [
        "long_data[\"value2\"] = np.random.standard_normal(len(long_data))\n",
        "long_data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " By omitting the last argument, you obtain a DataFrame with hierarchical columns"
      ],
      "metadata": {
        "id": "mY_nmrmbk51F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKlhCAnOfv9T"
      },
      "outputs": [],
      "source": [
        "pivoted = long_data.pivot(index=\"date\", columns=\"item\")\n",
        "pivoted.head()\n",
        "pivoted[\"value\"].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that pivot is equivalent to creating a hierarchical index using set_index fol\n",
        "lowed by a call to unstack:"
      ],
      "metadata": {
        "id": "oipe38hFk_4L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7_xm0W4fv9T"
      },
      "outputs": [],
      "source": [
        "unstacked = long_data.set_index([\"date\", \"item\"]).unstack(level=\"item\")\n",
        "unstacked.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Pivoting “Wide” to “Long” Format\n",
        " An inverse operation to pivot for DataFrames is pandas.melt. Rather than trans\n",
        "forming one column into many in a new DataFrame, it merges multiple columns into\n",
        " one, producing a DataFrame that is longer than the input. Let’s look at an example:"
      ],
      "metadata": {
        "id": "O-NuzRxYlDr3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bnz005h0fv9T"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"key\": [\"foo\", \"bar\", \"baz\"],\n",
        "                   \"A\": [1, 2, 3],\n",
        "                   \"B\": [4, 5, 6],\n",
        "                   \"C\": [7, 8, 9]})\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The \"key\" column may be a group indicator, and the other columns are data values.\n",
        " When using pandas.melt, we must indicate which columns (if any) are group indica\n",
        "tors. Let’s use \"key\" as the only group indicator here:"
      ],
      "metadata": {
        "id": "Yy2xj1EtlGnj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQy30SOafv9T"
      },
      "outputs": [],
      "source": [
        "melted = pd.melt(df, id_vars=\"key\")\n",
        "melted"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using pivot, we can reshape back to the original layout"
      ],
      "metadata": {
        "id": "PY1PVpeklKA9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_A3Lkwufv9T"
      },
      "outputs": [],
      "source": [
        "reshaped = melted.pivot(index=\"key\", columns=\"variable\",\n",
        "                        values=\"value\")\n",
        "reshaped"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Since the result of pivot creates an index from the column used as the row labels, we\n",
        " may want to use reset_index to move the data back into a column:"
      ],
      "metadata": {
        "id": "0g8jVcYHlLuK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z22tAblLfv9T"
      },
      "outputs": [],
      "source": [
        "reshaped.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " You can also specify a subset of columns to use as value columns"
      ],
      "metadata": {
        "id": "0R_NvzsVlNWX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djYWW16zfv9U"
      },
      "outputs": [],
      "source": [
        "pd.melt(df, id_vars=\"key\", value_vars=[\"A\", \"B\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " pandas.melt can be used without any group identifiers, too:"
      ],
      "metadata": {
        "id": "1_JabsKalO2Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnehC3vrfv9U"
      },
      "outputs": [],
      "source": [
        "pd.melt(df, value_vars=[\"A\", \"B\", \"C\"])\n",
        "pd.melt(df, value_vars=[\"key\", \"A\", \"B\"])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}